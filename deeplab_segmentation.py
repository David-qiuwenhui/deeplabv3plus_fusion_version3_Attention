import colorsys
import copy
import json

import cv2
import numpy as np
import torch
import torch.nn.functional as F
from PIL import Image
from torch import nn

from nets.deeplabv3_plus import DeepLab
from utils.utils import (
    cvtColor,
    preprocess_input,
    resize_image,
    show_config,
    time_synchronized,
)

# -------------------------------------------------#
#   mix_typeå‚æ•°ç”¨äºæ§åˆ¶æ£€æµ‹ç»“æœçš„å¯è§†åŒ–æ–¹å¼
#
#   mix_type = 0çš„æ—¶å€™ä»£è¡¨åŸå›¾ä¸ç”Ÿæˆçš„å›¾è¿›è¡Œæ··åˆ
#   mix_type = 1çš„æ—¶å€™ä»£è¡¨ä»…ä¿ç•™ç”Ÿæˆçš„å›¾
#   mix_type = 2çš„æ—¶å€™ä»£è¡¨ä»…æ‰£å»èƒŒæ™¯ï¼Œä»…ä¿ç•™åŸå›¾ä¸­çš„ç›®æ ‡
# -------------------------------------------------#


class DeeplabV3_Segmentation(object):
    # ---------------------------------------------------#
    #   åˆå§‹åŒ–Deeplab
    # ---------------------------------------------------#
    def __init__(
        self,
        model_path,
        num_classes,
        backbone,
        input_shape,
        downsample_factor,
        aux,
        mix_type,
        cuda,
        deploy,
        **kwargs,
    ):
        self._defaults = {}
        self._defaults["model_path"] = model_path
        self._defaults["num_classes"] = num_classes
        self._defaults["backbone"] = backbone
        self._defaults["input_shape"] = input_shape
        self._defaults["downsample_factor"] = downsample_factor
        self._defaults["aux"] = aux
        self._defaults["mix_type"] = mix_type
        self._defaults["cuda"] = cuda
        self._defaults["deploy"] = deploy
        self.__dict__.update(self._defaults)

        for name, value in kwargs.items():
            setattr(self, name, value)
        # ---------------------------------------------------#
        #   ç”»æ¡†è®¾ç½®ä¸åŒçš„é¢œè‰²
        # ---------------------------------------------------#
        if self.num_classes <= 21:
            self.colors = [
                (0, 0, 0),
                (0, 0, 128),
                (0, 128, 128),
                (128, 0, 0),
                (128, 0, 128),
                (128, 128, 0),
                (128, 128, 128),
            ]
        else:
            hsv_tuples = [
                (x / self.num_classes, 1.0, 1.0) for x in range(self.num_classes)
            ]
            self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))
            self.colors = list(
                map(
                    lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),
                    self.colors,
                )
            )

        # ---------- è¯»å–è°ƒè‰²æ¿ ----------
        palette_path = "./palette_suim.json"
        with open(palette_path, "rb") as f:
            palette_dict = json.load(f)
            palette = []
            for v in palette_dict.values():
                palette += v
        self.palette = palette

        # ---------------------------------------------------#
        #   è·å¾—æ¨¡å‹
        # ---------------------------------------------------#
        self.generate()
        # æ‰“å°è¶…å‚æ•°
        show_config(**self._defaults)

    # ---------------------------------------------------#
    #   è·å¾—æ‰€æœ‰çš„åˆ†ç±»
    # ---------------------------------------------------#
    def generate(self):
        # -------------------------------#
        #   è½½å…¥æ¨¡å‹ä¸æƒå€¼
        # -------------------------------#
        self.net = DeepLab(
            self.num_classes, self.backbone, self.downsample_factor, aux_branch=self.aux
        )

        device_type = None
        if torch.cuda.is_available() and self.cuda:
            device_type = "cuda"
        else:
            device_type = "cpu"
        print(f"\033[1;36;46m ğŸ”ŒğŸ”ŒğŸ”ŒğŸ”ŒUse {device_type} for predicting \033[0m")
        device = torch.device(device_type)
        # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # è½½å…¥è®­ç»ƒå®Œæˆçš„æ¨¡å‹æƒé‡
        self.net.load_state_dict(
            torch.load(self.model_path, map_location=device), strict=False
        )
        # repvggåˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼éœ€è¦å…ˆè½½å…¥æ¨¡å‹çš„è®­ç»ƒæƒé‡å‚æ•° å†åˆ‡æ¢æˆéƒ¨ç½²æ¨¡å¼
        if self.deploy:
            self.net.switch_to_deploy()
        self.net = self.net.eval()
        print("{} model, and classes loaded.".format(self.model_path))
        if self.cuda:
            self.net = nn.DataParallel(self.net)
            self.net = self.net.cuda()

    # ---------------------------------------------------#
    #   æ£€æµ‹å›¾ç‰‡
    # ---------------------------------------------------#
    def detect_image(self, image, count=False, name_classes=None):
        # ---------------------------------------------------------#
        #   åœ¨è¿™é‡Œå°†å›¾åƒè½¬æ¢æˆRGBå›¾åƒï¼Œé˜²æ­¢ç°åº¦å›¾åœ¨é¢„æµ‹æ—¶æŠ¥é”™ã€‚
        #   ä»£ç ä»…ä»…æ”¯æŒRGBå›¾åƒçš„é¢„æµ‹ï¼Œæ‰€æœ‰å…¶å®ƒç±»å‹çš„å›¾åƒéƒ½ä¼šè½¬åŒ–æˆRGB
        # ---------------------------------------------------------#
        image = cvtColor(image)
        # ---------------------------------------------------#
        #   å¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸€ä¸ªå¤‡ä»½ï¼Œåé¢ç”¨äºç»˜å›¾
        # ---------------------------------------------------#
        old_img = copy.deepcopy(image)
        orininal_h = np.array(image).shape[0]
        orininal_w = np.array(image).shape[1]
        # ---------------------------------------------------------#
        #   ç»™å›¾åƒå¢åŠ ç°æ¡ï¼Œå®ç°ä¸å¤±çœŸçš„resize
        #   ä¹Ÿå¯ä»¥ç›´æ¥resizeè¿›è¡Œè¯†åˆ«
        # ---------------------------------------------------------#
        image_data, nw, nh = resize_image(
            image, (self.input_shape[1], self.input_shape[0])
        )
        # ---------------------------------------------------------#
        #   æ·»åŠ ä¸Šbatch_sizeç»´åº¦
        # ---------------------------------------------------------#
        image_data = np.expand_dims(
            np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)),
            0,
        )

        with torch.no_grad():
            images = torch.from_numpy(image_data)
            if self.cuda:
                images = images.cuda()
            # ---------------------------------------------------#
            #   å›¾ç‰‡ä¼ å…¥ç½‘ç»œè¿›è¡Œé¢„æµ‹
            # ---------------------------------------------------#
            pr = self.net(images).main
            pr = pr.squeeze(dim=0)
            # ---------------------------------------------------#
            #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
            # ---------------------------------------------------#
            pr = F.softmax(pr.permute(1, 2, 0), dim=-1).cpu().numpy()
            # --------------------------------------#
            #   å°†ç°æ¡éƒ¨åˆ†æˆªå–æ‰
            # --------------------------------------#
            pr = pr[
                int((self.input_shape[0] - nh) // 2) : int(
                    (self.input_shape[0] - nh) // 2 + nh
                ),
                int((self.input_shape[1] - nw) // 2) : int(
                    (self.input_shape[1] - nw) // 2 + nw
                ),
            ]
            # ---------------------------------------------------#
            #   è¿›è¡Œå›¾ç‰‡çš„resize
            # ---------------------------------------------------#
            pr = cv2.resize(
                pr, (orininal_w, orininal_h), interpolation=cv2.INTER_LINEAR
            )
            # ---------------------------------------------------#
            #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
            # ---------------------------------------------------#
            pr = pr.argmax(axis=-1)

        # ---------------------------------------------------------#
        #   è®¡æ•°
        # ---------------------------------------------------------#
        if count:
            classes_nums = np.zeros([self.num_classes])
            total_points_num = orininal_h * orininal_w
            print("-" * 63)
            print("|%25s | %15s | %15s|" % ("Key", "Value", "Ratio"))
            print("-" * 63)
            for i in range(self.num_classes):
                num = np.sum(pr == i)
                ratio = num / total_points_num * 100
                if num > 0:
                    print(
                        "|%25s | %15s | %14.2f%%|"
                        % (str(name_classes[i]), str(num), ratio)
                    )
                    print("-" * 63)
                classes_nums[i] = num
            print("classes_nums:", classes_nums)

        if self.mix_type == 0:
            # seg_img = np.zeros((np.shape(pr)[0], np.shape(pr)[1], 3))
            # for c in range(self.num_classes):
            #     seg_img[:, :, 0] += ((pr[:, :] == c ) * self.colors[c][0]).astype('uint8')
            #     seg_img[:, :, 1] += ((pr[:, :] == c ) * self.colors[c][1]).astype('uint8')
            #     seg_img[:, :, 2] += ((pr[:, :] == c ) * self.colors[c][2]).astype('uint8')
            seg_img = np.reshape(
                np.array(self.colors, np.uint8)[np.reshape(pr, [-1])],
                [orininal_h, orininal_w, -1],
            )
            # ------------------------------------------------#
            #   å°†æ–°å›¾ç‰‡è½¬æ¢æˆImageçš„å½¢å¼
            # ------------------------------------------------#
            image = Image.fromarray(np.uint8(seg_img))
            # ------------------------------------------------#
            #   å°†æ–°å›¾ä¸åŸå›¾åŠè¿›è¡Œæ··åˆ
            # ------------------------------------------------#
            image = Image.blend(old_img, image, 0.7)

        elif self.mix_type == 1:
            # seg_img = np.zeros((np.shape(pr)[0], np.shape(pr)[1], 3))
            # for c in range(self.num_classes):
            #     seg_img[:, :, 0] += ((pr[:, :] == c ) * self.colors[c][0]).astype('uint8')
            #     seg_img[:, :, 1] += ((pr[:, :] == c ) * self.colors[c][1]).astype('uint8')
            #     seg_img[:, :, 2] += ((pr[:, :] == c ) * self.colors[c][2]).astype('uint8')
            seg_img = np.reshape(
                np.array(self.colors, np.uint8)[np.reshape(pr, [-1])],
                [orininal_h, orininal_w, -1],
            )
            # ------------------------------------------------#
            #   å°†æ–°å›¾ç‰‡è½¬æ¢æˆImageçš„å½¢å¼
            # ------------------------------------------------#
            image = Image.fromarray(np.uint8(seg_img))

        elif self.mix_type == 2:
            seg_img = (
                np.expand_dims(pr != 0, -1) * np.array(old_img, np.float32)
            ).astype("uint8")
            # ------------------------------------------------#
            #   å°†æ–°å›¾ç‰‡è½¬æ¢æˆImageçš„å½¢å¼
            # ------------------------------------------------#
            image = Image.fromarray(np.uint8(seg_img))

        return image

    def get_FPS(self, image, test_interval):
        from tqdm import tqdm

        # ---------------------------------------------------------#
        #   åœ¨è¿™é‡Œå°†å›¾åƒè½¬æ¢æˆRGBå›¾åƒï¼Œé˜²æ­¢ç°åº¦å›¾åœ¨é¢„æµ‹æ—¶æŠ¥é”™ã€‚
        #   ä»£ç ä»…ä»…æ”¯æŒRGBå›¾åƒçš„é¢„æµ‹ï¼Œæ‰€æœ‰å…¶å®ƒç±»å‹çš„å›¾åƒéƒ½ä¼šè½¬åŒ–æˆRGB
        # ---------------------------------------------------------#
        image = cvtColor(image)
        # ---------------------------------------------------------#
        #   ç»™å›¾åƒå¢åŠ ç°æ¡ï¼Œå®ç°ä¸å¤±çœŸçš„resize
        #   ä¹Ÿå¯ä»¥ç›´æ¥resizeè¿›è¡Œè¯†åˆ«
        # ---------------------------------------------------------#
        image_data, nw, nh = resize_image(
            image, (self.input_shape[1], self.input_shape[0])
        )
        # ---------------------------------------------------------#
        #   æ·»åŠ ä¸Šbatch_sizeç»´åº¦
        # ---------------------------------------------------------#
        image_data = np.expand_dims(
            np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)),
            0,
        )

        with torch.no_grad():
            images = torch.from_numpy(image_data)
            if self.cuda:
                images = images.cuda()

            # ---------------------------------------------------#
            #   å›¾ç‰‡ä¼ å…¥ç½‘ç»œè¿›è¡Œé¢„æµ‹
            # ---------------------------------------------------#
            pr = self.net(images).main
            pr = pr.squeeze(dim=0)
            # ---------------------------------------------------#
            #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
            # ---------------------------------------------------#
            pr = F.softmax(pr.permute(1, 2, 0), dim=-1).cpu().numpy().argmax(axis=-1)
            # --------------------------------------#
            #   å°†ç°æ¡éƒ¨åˆ†æˆªå–æ‰
            # --------------------------------------#
            pr = pr[
                int((self.input_shape[0] - nh) // 2) : int(
                    (self.input_shape[0] - nh) // 2 + nh
                ),
                int((self.input_shape[1] - nw) // 2) : int(
                    (self.input_shape[1] - nw) // 2 + nw
                ),
            ]

        t1 = time_synchronized()
        for _ in tqdm(range(test_interval)):
            with torch.no_grad():
                # ---------------------------------------------------#
                #   å›¾ç‰‡ä¼ å…¥ç½‘ç»œè¿›è¡Œé¢„æµ‹
                # ---------------------------------------------------#
                pr = self.net(images).main
                pr = pr.squeeze(dim=0)
                # ---------------------------------------------------#
                #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
                # ---------------------------------------------------#
                pr = (
                    F.softmax(pr.permute(1, 2, 0), dim=-1).cpu().numpy().argmax(axis=-1)
                )
                # --------------------------------------#
                #   å°†ç°æ¡éƒ¨åˆ†æˆªå–æ‰
                # --------------------------------------#
                pr = pr[
                    int((self.input_shape[0] - nh) // 2) : int(
                        (self.input_shape[0] - nh) // 2 + nh
                    ),
                    int((self.input_shape[1] - nw) // 2) : int(
                        (self.input_shape[1] - nw) // 2 + nw
                    ),
                ]
        tact_time = (time_synchronized() - t1) / test_interval
        return tact_time

    def get_miou_png(self, image):
        # ---------------------------------------------------------#
        #   åœ¨è¿™é‡Œå°†å›¾åƒè½¬æ¢æˆRGBå›¾åƒï¼Œé˜²æ­¢ç°åº¦å›¾åœ¨é¢„æµ‹æ—¶æŠ¥é”™ã€‚
        #   ä»£ç ä»…ä»…æ”¯æŒRGBå›¾åƒçš„é¢„æµ‹ï¼Œæ‰€æœ‰å…¶å®ƒç±»å‹çš„å›¾åƒéƒ½ä¼šè½¬åŒ–æˆRGB
        # ---------------------------------------------------------#
        image = cvtColor(image)
        orininal_h = np.array(image).shape[0]
        orininal_w = np.array(image).shape[1]
        # ---------------------------------------------------------#
        #   ç»™å›¾åƒå¢åŠ ç°æ¡ï¼Œå®ç°ä¸å¤±çœŸçš„resize
        #   ä¹Ÿå¯ä»¥ç›´æ¥resizeè¿›è¡Œè¯†åˆ«
        # ---------------------------------------------------------#
        image_data, nw, nh = resize_image(
            image, (self.input_shape[1], self.input_shape[0])
        )
        # ---------------------------------------------------------#
        #   æ·»åŠ ä¸Šbatch_sizeç»´åº¦
        # ---------------------------------------------------------#
        image_data = np.expand_dims(
            np.transpose(preprocess_input(np.array(image_data, np.float32)), (2, 0, 1)),
            0,
        )

        with torch.no_grad():
            images = torch.from_numpy(image_data)
            if self.cuda:
                images = images.cuda()

            # ---------------------------------------------------#
            #   å›¾ç‰‡ä¼ å…¥ç½‘ç»œè¿›è¡Œé¢„æµ‹
            # ---------------------------------------------------#
            pr = self.net(images).main
            pr = pr.squeeze(dim=0)
            # ---------------------------------------------------#
            #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
            # ---------------------------------------------------#
            pr = F.softmax(pr.permute(1, 2, 0), dim=-1).cpu().numpy()
            # --------------------------------------#
            #   å°†ç°æ¡éƒ¨åˆ†æˆªå–æ‰
            # --------------------------------------#
            pr = pr[
                int((self.input_shape[0] - nh) // 2) : int(
                    (self.input_shape[0] - nh) // 2 + nh
                ),
                int((self.input_shape[1] - nw) // 2) : int(
                    (self.input_shape[1] - nw) // 2 + nw
                ),
            ]
            # ---------------------------------------------------#
            #   è¿›è¡Œå›¾ç‰‡çš„resize
            # ---------------------------------------------------#
            pr = cv2.resize(
                pr, (orininal_w, orininal_h), interpolation=cv2.INTER_LINEAR
            )
            # ---------------------------------------------------#
            #   å–å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç§ç±»
            # ---------------------------------------------------#
            pr = pr.argmax(axis=-1)

        mask = Image.fromarray(np.uint8(pr))
        mask.putpalette(self.palette, rawmode="BGR")
        return mask
